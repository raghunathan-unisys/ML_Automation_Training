{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix this code file. \n",
    "# It did not work even when the instructor tried it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'8e0b99a0dc08403cb8f02cd4c03f299d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcognitiveservices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingStatusType, Person, QualityForRecognition\n\u001b[0;32m     18\u001b[0m \u001b[39m# This key will serve all examples in this document.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# KEY = os.environ[\"VISION_KEY\"]\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m KEY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39m8e0b99a0dc08403cb8f02cd4c03f299d\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     22\u001b[0m \u001b[39m# This endpoint will be used in all examples in this quickstart.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# ENDPOINT = os.environ[\"VISION_ENDPOINT\"]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m ENDPOINT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mhttps://mlaitraining.cognitiveservices.azure.com/\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m<frozen os>:685\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '8e0b99a0dc08403cb8f02cd4c03f299d'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition\n",
    "\n",
    "\n",
    "# This key will serve all examples in this document.\n",
    "# KEY = os.environ[\"VISION_KEY\"]\n",
    "KEY = os.environ['8e0b99a0dc08403cb8f02cd4c03f299d']\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "# ENDPOINT = os.environ[\"VISION_ENDPOINT\"]\n",
    "ENDPOINT = os.environ[\"https://mlaitraining.cognitiveservices.azure.com/\"]\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/'\n",
    "\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Child\")\n",
    "\n",
    "'''\n",
    "Detect faces and register them to each person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory (TBD pull from web instead)\n",
    "woman_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Mom1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Mom2.jpg\"]\n",
    "man_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Dad1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Dad2.jpg\"]\n",
    "child_images = [\"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Son1.jpg\", \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/Family1-Son2.jpg\"]\n",
    "\n",
    "# Add to woman person\n",
    "for image in woman_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, woman.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, woman.person_id))\n",
    "\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "# Add to man person\n",
    "for image in man_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, man.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, man.person_id))\n",
    "\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "# Add to child person\n",
    "for image in child_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            print(\"{} has insufficient quality\".format(face))\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, child.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, child.person_id))\n",
    "    if not sufficientQuality: continue\n",
    "\n",
    "\n",
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)\n",
    "\n",
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "# test_image = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/identification1.jpg\"\n",
    "test_image = \".data/identification1.jpg\"\n",
    "\n",
    "print('Pausing for 10 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (10)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_url(test_image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in image')\n",
    "if not results:\n",
    "    print('No person identified in the person group')\n",
    "for identifiedFace in results:\n",
    "    if len(identifiedFace.candidates) > 0:\n",
    "        print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "        # Verify faces\n",
    "        verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "        print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "    else:\n",
    "        print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))\n",
    " \n",
    "\n",
    "print()\n",
    "print('End of quickstart.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
